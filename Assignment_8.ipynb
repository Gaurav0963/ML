{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8913dbd5",
   "metadata": {},
   "source": [
    "# Assignment 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e63f0",
   "metadata": {},
   "source": [
    "### Q1. What exactly is a feature? Give an example to illustrate your point.\n",
    "\n",
    "ANSWER : In data science and machine learning, a feature is an individual measurable property or characteristic of a phenomenon being observed. i.e., a feature is a piece of data that is used as an input to a machine learning model to help it make predictions or classifications.\n",
    "\n",
    "For example, let's consider a dataset that contains information about housing prices in a particular city. The dataset might include features such as the number of bedrooms, the square footage of the property, the location of the property, and the age of the property. Each of these features provides information that can be used to help predict the price of a house."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6ab39",
   "metadata": {},
   "source": [
    "### Q2. What are the various circumstances in which feature construction is required?\n",
    "\n",
    "ANSWER : Feature construction, also known as feature engineering, is the process of creating new features from existing data that can improve the performance of a machine learning model. Feature construction is often required in the following circumstances:\n",
    "\n",
    "1. `Missing data` : If a dataset contains missing values for certain features, feature construction techniques can be used to create new features that help fill in the missing data.\n",
    "\n",
    "2. `Non-linear relationships` : If the relationship between the target variable and one or more of the input features is non-linear, feature construction can be used to create new features that capture this non-linear relationship.\n",
    "\n",
    "3. `Dimensionality reduction` : Feature construction can be used to reduce the dimensionality of a dataset by creating new features that summarize or represent the information contained in multiple input features.\n",
    "\n",
    "4. `Feature selection` : Feature construction can be used to create new features that are more relevant or informative for a particular machine learning task than the existing input features.\n",
    "\n",
    "5. `Domain expertise` : Feature construction can be used to incorporate domain-specific knowledge or insights into a machine learning model by creating new features that are tailored to the specific problem or domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b318eaf",
   "metadata": {},
   "source": [
    "### Q3. Describe how nominal variables are encoded.\n",
    "\n",
    "ANSWER : `Nominal variables`, also known as `categorical variables`, are a type of variable in machine learning that represent discrete, unordered categories or classes. Nominal variables do not have an inherent order or ranking, unlike ordinal variables which have a clear ranking.\n",
    "\n",
    "Nominal variables are often used to represent qualitative or categorical data, such as the type of car (sedan, SUV, pickup truck), gender (male, female, non-binary), or color (red, blue, green). They are distinct from continuous variables, which represent numeric data that can take on any value within a range, such as height, weight, or temperature.\n",
    "\n",
    "Here are 5 common ways to encode nominal variables in machine learning:\n",
    "\n",
    "1. One-Hot Encoding: One-hot encoding is a method of representing categorical variables as binary vectors. Each category of the variable is given a separate binary variable, with a value of 1 indicating the presence of that category and a value of 0 indicating its absence. For example, if a variable has three categories: \"red\", \"green\", and \"blue\", it would be encoded as `[1, 0, 0], [0, 1, 0], or [0, 0, 1]` respectively.\n",
    "\n",
    "\n",
    "2. Binary Encoding: Binary encoding is a method that reduces the dimensionality of one-hot encoding by representing each category as a binary number. Each category is assigned a unique number and then converted to a binary representation. For example, if a variable has three categories: \"red\", \"green\", and \"blue\", it would be encoded as `[0, 0], [0, 1], or [1, 0]` respectively.\n",
    "\n",
    "\n",
    "3. Label Encoding: Label encoding is a method of representing categorical variables as integers. Each category of the variable is assigned a unique integer, with no particular order or rank. For example, if a variable has three categories: \"red\", \"green\", and \"blue\", it would be encoded as 0, 1, or 2 respectively.\n",
    "\n",
    "\n",
    "4. Count Encoding: Count encoding is a method of representing categorical variables by their frequency in the dataset. Each category of the variable is assigned a count of the number of times it appears in the dataset. For example, if a variable has three categories: \"red\", \"green\", and \"blue\", and \"red\" appears 10 times, \"green\" appears 20 times, and \"blue\" appears 30 times, it would be encoded as 10, 20, and 30 respectively.\n",
    "\n",
    "\n",
    "5. Target Encoding: Target encoding is a method of representing categorical variables by their relationship to the target variable. Each category of the variable is assigned the mean of the target variable for that category. For example, if a variable has three categories: \"red\", \"green\", and \"blue\", and the target variable is binary (0 or 1), the mean of the target variable for each category would be calculated and used as the encoding.\n",
    "\n",
    "\n",
    "Nominal variables are an important type of data in machine learning and can be used in a variety of applications, such as text classification, image recognition, and sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c3a85",
   "metadata": {},
   "source": [
    "### Q4. Describe how numeric features are converted to categorical features.\n",
    "\n",
    "ANSWER : Numeric features can be converted to categorical features by dividing the numeric range into a fixed number of bins or categories. This process is known as `binning` or `discretization`. Here are the steps involved:\n",
    "\n",
    "1. Determine the number of categories you want to create. This can be based on the distribution of the numeric feature or the specific requirements of your problem.\n",
    "\n",
    "2. Divide the range of the numeric feature into equal-sized intervals or bins. You can use different strategies to define the bin boundaries, such as the width of the bins or percentiles of the distribution.\n",
    "\n",
    "3. Assign each value of the numeric feature to the corresponding bin or category. This can be done using a variety of methods, such as pandas cut function or numpy digitize function.\n",
    "\n",
    "4. Encode the categories using one of the methods described in the previous answer for nominal variable encoding, such as one-hot encoding or label encoding.\n",
    "\n",
    "For example, let's say we have a numeric feature \"age\" with values ranging from 18 to 80. We want to divide this range into 4 categories: \"young adult\" (18-30), \"adult\" (31-45), \"middle-aged\" (46-60), and \"senior\" (61-80). We can use the pandas cut function to create the categories and then encode them using one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ddc4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataframe with age values\n",
    "data = {'age': [25, 32, 47, 53, 70, 22, 40, 60, 18]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the bin boundaries for the categories\n",
    "bins = [17, 30, 45, 60, 80]\n",
    "\n",
    "# Create the categories using pandas cut function\n",
    "df['age_category'] = pd.cut(df['age'], bins=bins, labels=['young adult', 'adult', 'middle-aged', 'senior'])\n",
    "\n",
    "# Encode the categories using one-hot encoding\n",
    "encoded_df = pd.get_dummies(df, columns=['age_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a230d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_category_young adult</th>\n",
       "      <th>age_category_adult</th>\n",
       "      <th>age_category_middle-aged</th>\n",
       "      <th>age_category_senior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  age_category_young adult  age_category_adult  \\\n",
       "0   25                         1                   0   \n",
       "1   32                         0                   1   \n",
       "2   47                         0                   0   \n",
       "3   53                         0                   0   \n",
       "4   70                         0                   0   \n",
       "5   22                         1                   0   \n",
       "6   40                         0                   1   \n",
       "7   60                         0                   0   \n",
       "8   18                         1                   0   \n",
       "\n",
       "   age_category_middle-aged  age_category_senior  \n",
       "0                         0                    0  \n",
       "1                         0                    0  \n",
       "2                         1                    0  \n",
       "3                         1                    0  \n",
       "4                         0                    1  \n",
       "5                         0                    0  \n",
       "6                         0                    0  \n",
       "7                         1                    0  \n",
       "8                         0                    0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01b765b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_category</th>\n",
       "      <th>Age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>young adult</td>\n",
       "      <td>18-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>adult</td>\n",
       "      <td>31-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>46-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>46-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>senior</td>\n",
       "      <td>61-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>young adult</td>\n",
       "      <td>18-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>adult</td>\n",
       "      <td>31-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>46-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>young adult</td>\n",
       "      <td>18-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age age_category Age_group\n",
       "0   25  young adult     18-30\n",
       "1   32        adult     31-45\n",
       "2   47  middle-aged     46-60\n",
       "3   53  middle-aged     46-60\n",
       "4   70       senior     61-80\n",
       "5   22  young adult     18-30\n",
       "6   40        adult     31-45\n",
       "7   60  middle-aged     46-60\n",
       "8   18  young adult     18-30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way of creating categories which is more readable.\n",
    "\n",
    "df['Age_group'] = pd.cut(df.age, bins=[17, 30, 45, 60, 80], labels = ['18-30', '31-45', '46-60', '61-80'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e1f217",
   "metadata": {},
   "source": [
    "### Q6. When is a feature considered irrelevant? What can be said to quantify it?\n",
    "\n",
    "ANSWER : A feature is considered irrelevant when it does not have any predictive power or contribution to the target variable in a machine learning model. An irrelevant feature can negatively impact the performance of the model by introducing noise or complexity, and it may also increase the training time and cost of the model.\n",
    "\n",
    "There are different methods to quantify the relevance or importance of a feature, such as:\n",
    "\n",
    "1. `Correlation analysis` : This method measures the linear relationship between the feature and the target variable using correlation coefficients such as Pearson's correlation or Spearman's rank correlation. If the correlation coefficient is close to zero, it indicates that the feature and the target variable are not correlated and the feature may be irrelevant.\n",
    "\n",
    "2. `Feature importance ranking` : This method ranks the features based on their contribution to the model performance or their ability to explain the variance of the target variable. There are several algorithms that can be used for feature importance ranking, such as decision trees, random forests, gradient boosting, or permutation importance. Features with low importance scores may be considered irrelevant.\n",
    "\n",
    "3. `Domain knowledge` : This method relies on the expertise and intuition of domain experts to determine whether a feature is relevant or not. For example, if a feature is known to be irrelevant or redundant based on prior knowledge or research, it may be removed from the model.\n",
    "\n",
    "It's important to note that the relevance of a feature may depend on the specific problem or context, and different features may be relevant for different models or tasks. Therefore, it's recommended to perform feature selection or feature engineering to identify and select the most relevant features for a particular machine learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e48bac6",
   "metadata": {},
   "source": [
    "### Q7. When is a function considered redundant? What criteria are used to identify features that could be redundant?\n",
    "\n",
    "ANSWER : A function is considered redundant when it provides the same information or behavior as another function or feature in a machine learning model. Redundant features can lead to _overfitting_, _increase the complexity of the model_, and _reduce the interpretability and generalization performance of the model._\n",
    "\n",
    "There are different criteria that can be used to identify features that could be redundant, such as:\n",
    "\n",
    "1. Correlation analysis: Redundant features may have high correlation coefficients with other features in the model. Therefore, a correlation analysis can be used to identify pairs or groups of highly correlated features, and one of them can be removed to reduce redundancy. `from dython.nominal import associations`, associations function from dython library can be used for this purpose, the function takes pandas dataFrame as input.\n",
    "\n",
    "2. Feature importance ranking: Redundant features may have low or negligible importance scores in a feature importance ranking analysis, as they may not contribute significantly to the model performance or information gain.\n",
    "\n",
    "3. Domain knowledge: Redundant features may be identified based on prior knowledge or research about the problem domain, the data sources, or the relationships between features.\n",
    "\n",
    "4. Model performance: Redundant features may not improve or may even worsen the performance metrics of the model, such as accuracy, AUC, or MSE, when compared to a model without those features. Therefore, evaluating the model performance with and without each feature can help to identify redundancies.\n",
    "\n",
    "5. Model complexity: Redundant features can increase the complexity of the model, such as the number of parameters, nodes, or layers in a neural network, which can lead to overfitting and poor generalization performance. Therefore, measuring the model complexity with and without each feature can help to identify redundancies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0daea5",
   "metadata": {},
   "source": [
    "### Q8. What are the various distance measurements used to determine feature similarity?\n",
    "\n",
    "ANSWER : There are several distance measurements used to determine feature similarity or dissimilarity in machine learning and data science, such as:\n",
    "\n",
    "1. Euclidean distance: This is the most commonly used distance metric, which measures the straight-line distance between two points in a multi-dimensional space. It is defined as the square root of the sum of squared differences between the corresponding feature values.\n",
    "\n",
    "2. Manhattan distance: This distance metric measures the sum of absolute differences between the corresponding feature values of two points, along each dimension.\n",
    "\n",
    "3. Chebyshev distance: This distance metric measures the maximum absolute difference between the corresponding feature values of two points, along any dimension.\n",
    "\n",
    "4. Cosine distance: This distance metric measures the cosine of the angle between two vectors in a multi-dimensional space. It is often used for text or document similarity, where the vectors represent the frequency or TF-IDF of words.\n",
    "\n",
    "5. Jaccard distance: This distance metric measures the dissimilarity between two sets of binary features, such as presence or absence of certain attributes. It is defined as the ratio of the size of the intersection to the size of the union of the sets.\n",
    "\n",
    "6. Hamming distance: This distance metric measures the number of positions at which the corresponding feature values of two points differ, for binary or categorical features.\n",
    "\n",
    "7. Mahalanobis distance: This distance metric takes into account the covariance and correlation between the feature dimensions, and is often used for high-dimensional data with complex relationships between the features.        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d81b32",
   "metadata": {},
   "source": [
    "### Q9. State difference between Euclidean and Manhattan distances?\n",
    "\n",
    "ANSWER : The main difference between Euclidean and Manhattan distances is the way they measure the distance between two points in a multi-dimensional space.\n",
    "\n",
    "* Euclidean distance measures the shortest straight-line distance between two points. It is calculated as the square root of the sum of the squared differences between the corresponding feature values. It is often used when the features have a continuous, numerical scale and the spatial relationship between the points is important. For example, in image recognition or clustering.\n",
    "    * Euclidean distance is more sensitive to differences in feature values\n",
    "\n",
    "* Manhattan distance, also known as _city block distance_ or _L1 distance_, measures the distance between two points by summing the absolute differences between the corresponding feature values along each dimension. It is called Manhattan distance because it is similar to the way people navigate in a city by moving along the city blocks. Manhattan distance is often used when the features have a discrete, categorical, or ordinal scale and the spatial relationship between the points is less important. For example, in text classification or feature selection.\n",
    "    * Manhattan distance is more robust to outliers and noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa4bb1",
   "metadata": {},
   "source": [
    "### Q10. Distinguish between feature transformation and feature selection.\n",
    "\n",
    "ANSWER : Feature transformation and feature selection are two important techniques used in machine learning for feature engineering.\n",
    "\n",
    "* Feature transformation involves converting or scaling the original features to a new representation that may be more suitable for the given task. This could involve applying mathematical functions such as logarithmic or exponential transformations, or scaling the features to have zero mean and unit variance. \n",
    "    * Feature transformation can help to make the features more interpretable, reduce noise or redundancy, or capture nonlinear relationships between the features. \n",
    "    * It involves changing the representation of the original features to capture more complex relationships or patterns\n",
    "    * Examples of feature transformation techniques include Principal Component Analysis (PCA), Non-negative Matrix Factorization (NMF), and t-SNE.\n",
    "\n",
    "* Feature selection involves selecting a subset of the original features that are most relevant or informative for the given task. This could involve ranking the features based on statistical tests, such as correlation or mutual information, or using model-based selection methods, such as Recursive Feature Elimination (RFE) or Lasso Regression. \n",
    "    * Feature selection can help to reduce overfitting, improve model accuracy, and simplify the model by removing irrelevant or redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778057d6",
   "metadata": {},
   "source": [
    "### Q11. Make brief notes on any two of the following:\n",
    "\n",
    "#### 1. SVD (Standard Variable Diameter Diameter)\n",
    "#### 2. Collection of features using a hybrid approach\n",
    "#### 3. The width of the silhouette\n",
    "#### 4. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3500f",
   "metadata": {},
   "source": [
    "__Make brief notes on Collection of features using a hybrid approach__\n",
    "\n",
    "* A hybrid approach to feature collection combines different methods to achieve better feature quality and diversity. Some common techniques used in a hybrid approach include:\n",
    "\n",
    "    1. Filter methods: These methods use statistical tests or correlation measures to rank the features based on their relevance to the target variable. Examples of filter methods include Chi-squared test, Information Gain, and Correlation-based Feature Selection.\n",
    "\n",
    "    2. Wrapper methods: These methods use a search strategy, such as forward selection or backward elimination, to evaluate the performance of a given set of features using a chosen machine learning algorithm. Examples of wrapper methods include Recursive Feature Elimination and Genetic Algorithm-based Feature Selection.\n",
    "\n",
    "    3. Embedded methods: These methods incorporate feature selection into the model training process, by selecting the most relevant features during model training. Examples of embedded methods include Lasso Regression, Ridge Regression, and Elastic Net.\n",
    "\n",
    "By combining these methods, a hybrid approach can take advantage of the strengths of each method and overcome their limitations. For example, filter methods can quickly identify the most relevant features but may not consider the interactions between features. Wrapper methods can handle feature interactions but may be computationally expensive. Embedded methods can handle feature interactions and reduce overfitting, but may require a larger dataset.\n",
    "\n",
    "Overall, a hybrid approach to feature collection can lead to better feature quality and diversity, resulting in improved machine learning performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967bf846",
   "metadata": {},
   "source": [
    "__Receiver operating characteristic curve__\n",
    "\n",
    "* A Receiver Operating Characteristic (ROC) curve is a graphical plot that summarizes the performance of a binary classification model by varying the decision threshold. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) for different threshold values.\n",
    "\n",
    "    * The true positive rate (TPR) is the proportion of actual positive cases that are correctly classified as positive by the model, while the false positive rate (FPR) is the proportion of actual negative cases that are incorrectly classified as positive by the model. By varying the decision threshold, the trade-off between TPR and FPR can be adjusted, which can affect the model's overall performance.\n",
    "\n",
    "    * The ROC curve can help to visualize the performance of a binary classifier, regardless of the decision threshold chosen, and to compare the performance of different classifiers. The area under the curve (AUC) of the ROC curve is a common summary statistic that measures the overall performance of the model. An AUC of 1.0 indicates a perfect classifier, while an AUC of 0.5 indicates a random classifier.\n",
    "\n",
    "    * The ROC curve is commonly used in medical diagnosis, information retrieval, and fraud detection, among other applications, where the cost of false positives and false negatives may differ and the decision threshold needs to be carefully selected to optimize the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30e5673a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression classifier\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for test data\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
